{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c01ad71-ae41-4707-9da6-dcc728b7cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021.12.04 / KwnakiAhn / How to setup pyspark on jupyuter\n",
    "\n",
    "# install java (https://m.blog.naver.com/opusk/220985259485)\n",
    "# !sudo apt-get install default-jdk\n",
    "\n",
    "# Install apache spark\n",
    "# !wget https://spark.apache.org/downloads.html \n",
    "# (wget https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz)\n",
    "# (wget https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz) / EMR release 6.0.0\n",
    "# !tar -xzf spark-1.2.0-bin-hadoop2.4.tgz\n",
    "# !sudo mv spark-3.2.0-bin-hadoop3.2 /opt/spark-3.2.0\n",
    "# !sudo ln -s /opt/spark-3.2.0 /opt/sparkÌ€\n",
    "# !export SPARK_HOME=/opt/spark\n",
    "# !export PATH=$SPARK_HOME/bin:$PATH\n",
    "\n",
    "# install pyspark\n",
    "# !pip install pyspark\n",
    "# !pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb7e26c-a28e-45e5-beac-37aa79672bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.2.0/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.2.0/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jupyter/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jupyter/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-49fa0a35-9428-4915-8ada-fe411ce45060;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 191ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-49fa0a35-9428-4915-8ada-fe411ce45060\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/7ms)\n",
      "21/12/05 01:22:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/05 01:22:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ[\"SPARK_HOME\"] = ['/opt/spark-2.3.0', '/opt/spark-2.4.4', '/opt/spark-3.2.0'][2]\n",
    "sys.path.insert(0, os.environ[\"SPARK_HOME\"])\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# 2021.12.04 / KwankiAhn / How to use graphframes in pyspark\n",
    "# 1. config('spark.jars.packages') = pyspark --packages graphframes:graphframes:0.6.0-spark2.3-s_2.11\n",
    "# 2. graphframes <-> spark version sensitive!\n",
    "#  a. https://spark-packages.org/package/graphframes/graphframes\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"GraphFramePractice1\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .config('spark.jars.packages', 'graphframes:graphframes:0.8.2-spark3.2-s_2.12')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c36f9f-982f-4d0c-87c9-b3b35ab1f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial guide : https://graphframes.github.io/graphframes/docs/_site/user-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdee803-f95b-4c0f-9165-a9faa94582d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex DataFrame\n",
    "v = sqlContext.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 36),\n",
    "  (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "# Edge DataFrame\n",
    "e = sqlContext.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a177b18-e059-40d1-9d19-4e3d2470e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices\n",
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 30|\n",
      "|  d|  David| 29|\n",
      "|  e| Esther| 32|\n",
      "|  f|  Fanny| 36|\n",
      "+---+-------+---+\n",
      "\n",
      "edges\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      friend|\n",
      "|  b|  c|      follow|\n",
      "|  c|  b|      follow|\n",
      "|  f|  c|      follow|\n",
      "|  e|  f|      follow|\n",
      "|  e|  d|      friend|\n",
      "|  d|  a|      friend|\n",
      "+---+---+------------+\n",
      "\n",
      "vertexInDegrees\n",
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  b|       2|\n",
      "|  c|       2|\n",
      "|  f|       1|\n",
      "|  d|       1|\n",
      "|  a|       1|\n",
      "+---+--------+\n",
      "\n",
      "+--------+\n",
      "|min(age)|\n",
      "+--------+\n",
      "|      29|\n",
      "+--------+\n",
      "\n",
      "numFollows: 4\n"
     ]
    }
   ],
   "source": [
    "from graphframes.examples import Graphs\n",
    "g = Graphs(spark).friends()\n",
    "print(\"vertices\"); g.vertices.show(); print(\"edges\"); g.edges.show()\n",
    "\n",
    "# Get a DataFrame with columns \"id\" and \"inDegree\" (in-degree)\n",
    "vertexInDegrees = g.inDegrees\n",
    "print(\"vertexInDegrees\"); vertexInDegrees.show()\n",
    "\n",
    "# Find the youngest user's age in the graph.\n",
    "# This queries the vertex DataFrame.\n",
    "g.vertices.groupBy().min(\"age\").show()\n",
    "\n",
    "# Count the number of \"follows\" in the graph.\n",
    "# This queries the edge DataFrame.\n",
    "numFollows = g.edges.filter(\"relationship = 'follow'\").count()\n",
    "print(f\"numFollows: {numFollows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a054e9c-412a-4f54-9fe6-8716bbd48e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifs\n",
      "+----------------+--------------+----------------+--------------+\n",
      "|               a|             e|               b|            e2|\n",
      "+----------------+--------------+----------------+--------------+\n",
      "|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|{b, c, follow}|\n",
      "|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|{c, b, follow}|\n",
      "+----------------+--------------+----------------+--------------+\n",
      "\n",
      "motifs query : b.age > 30\n",
      "+----------------+--------------+------------+--------------+\n",
      "|               a|             e|           b|            e2|\n",
      "+----------------+--------------+------------+--------------+\n",
      "|{c, Charlie, 30}|{c, b, follow}|{b, Bob, 36}|{b, c, follow}|\n",
      "+----------------+--------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from graphframes.examples import Graphs\n",
    "g = Graphs(spark).friends()  # Get example graph\n",
    "\n",
    "# Search for pairs of vertices with edges in both directions between them.\n",
    "motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n",
    "print(\"motifs\"); motifs.show()\n",
    "\n",
    "# More complex queries can be expressed by applying filters.\n",
    "print(\"motifs query : b.age > 30\"); motifs.filter(\"b.age > 30\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70759f3f-b6d3-4915-9265-f2903263808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain4\n",
      "+----------------+--------------+----------------+--------------+----------------+--------------+----------------+\n",
      "|               a|            ab|               b|            bc|               c|            cd|               d|\n",
      "+----------------+--------------+----------------+--------------+----------------+--------------+----------------+\n",
      "| {e, Esther, 32}|{e, d, friend}|  {d, David, 29}|{d, a, friend}|  {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|\n",
      "| {e, Esther, 32}|{e, f, follow}|  {f, Fanny, 36}|{f, c, follow}|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|\n",
      "|  {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|\n",
      "|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|\n",
      "|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|\n",
      "|  {f, Fanny, 36}|{f, c, follow}|{c, Charlie, 30}|{c, b, follow}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|\n",
      "|  {d, David, 29}|{d, a, friend}|  {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|\n",
      "+----------------+--------------+----------------+--------------+----------------+--------------+----------------+\n",
      "\n",
      "chainWith2Friends2\n",
      "+---------------+--------------+--------------+--------------+--------------+--------------+----------------+\n",
      "|              a|            ab|             b|            bc|             c|            cd|               d|\n",
      "+---------------+--------------+--------------+--------------+--------------+--------------+----------------+\n",
      "|{e, Esther, 32}|{e, d, friend}|{d, David, 29}|{d, a, friend}|{a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|\n",
      "| {d, David, 29}|{d, a, friend}|{a, Alice, 34}|{a, b, friend}|  {b, Bob, 36}|{b, c, follow}|{c, Charlie, 30}|\n",
      "+---------------+--------------+--------------+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql.types import IntegerType\n",
    "from functools import reduce\n",
    "\n",
    "chain4 = g.find(\"(a)-[ab]->(b); (b)-[bc]->(c); (c)-[cd]->(d)\")\n",
    "print(\"chain4\"); chain4.show()\n",
    "\n",
    "# Query on sequence, with state (cnt)\n",
    "#  (a) Define method for updating state given the next element of the motif.\n",
    "sumFriends = lambda cnt, relationship: when(relationship == \"friend\", cnt + 1).otherwise(cnt)\n",
    "#  (b) Use sequence operation to apply method to sequence of elements in motif.\n",
    "#      In this case, the elements are the 3 edges.\n",
    "condition = reduce(lambda cnt, e: sumFriends(cnt, col(e).relationship), [\"ab\", \"bc\", \"cd\"], lit(0))\n",
    "#  (c) Apply filter to DataFrame.\n",
    "chainWith2Friends2 = chain4.where(condition >= 2)\n",
    "print(\"chainWith2Friends2\"); chainWith2Friends2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5326c607-27f4-475a-b6b5-33daa2deb386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abbccd'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda a, b: a + b, [\"ab\", \"bc\", \"cd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed20d7-cb30-498c-8b2f-22efd7ccbe2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
